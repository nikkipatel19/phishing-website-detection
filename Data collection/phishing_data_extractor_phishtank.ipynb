{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    level='INFO',\n",
    "                    filename='phish_scrap.log')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "host_url = \"https://phishtank.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ErrorResponse:\n",
    "    error: str\n",
    "    status_code: int = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_api(url):\n",
    "    try:\n",
    "        return requests.get(url)\n",
    "    except Exception as e:\n",
    "        message = f\"while processing your {url=}\\nwe got the exception {e}\"\n",
    "        logger.error(message)\n",
    "        return ErrorResponse(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_page_up_or_down(url):\n",
    "    response = send_api(url)\n",
    "    return 'Active' if response.status_code == 200 else 'Not Active'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phishing_url(id_url):\n",
    "    time.sleep(3)\n",
    "    logger.info(f\"{id_url=} is processing\")\n",
    "    id_url = id_url.strip()\n",
    "    response = send_api(id_url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        logger.error(f\"Failed to fetch data from {id_url}\")\n",
    "        return None, None\n",
    "    \n",
    "    soup = BeautifulSoup(response.text)\n",
    "    phish_urls = soup.find_all(name='b')\n",
    "    phish_urls = [link for phish_url in phish_urls if (link:=(phish_url.string)) and 'http' in link]\n",
    "    phish_url = phish_urls[0] if phish_urls else None\n",
    "    is_active = check_page_up_or_down(phish_url)\n",
    "    return phish_url, is_active\n",
    "        \n",
    "    # return ''.join(phish_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phish_ids_in_page(page):\n",
    "     logger.info(f\"processing {page=}\")\n",
    "     search_url = f\"phish_search.php?page={page}&active=y&verified=u\"\n",
    "     response = send_api(f\"{host_url}/{search_url}\")\n",
    "     soup = BeautifulSoup(response.text)\n",
    "     links = soup.find_all(name='a')\n",
    "     ids = {f\"{host_url}/{url}\": get_phishing_url(f\"{host_url}/{url}\") for link in links if (url:=link.get('href')) and 'phish_detail.php?phish_id=' in url}\n",
    "     return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_phish_ids(pagination=1000):\n",
    "    phish_ids = dict()\n",
    "    for page in range(pagination):\n",
    "        ids = get_phish_ids_in_page(page)\n",
    "        phish_ids |= ids\n",
    "    return phish_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "phish_url_dict = scrap_phish_ids(pagination=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "phish_ids_df = pd.DataFrame({\n",
    "    \"phish_id_url\": phish_url_dict.keys(), \n",
    "    \"phish_url\": [url for url, _ in phish_url_dict.values()], \n",
    "    'active_state': [active for _, active in phish_url_dict.values()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_ids_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phish_ids_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "phish_ids_df.to_csv('phish_urls_demo.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
